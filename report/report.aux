\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{Definition}{1}{Doc-Start}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A “slice” of an MSI dataset for a specific $m/z$ (or associated ion). The inner part of manually outlined region (in red) is a sample area, the outside area is off sample (or background). Here we have an example of a signal that mostly comes (more intense signals are yellow) from the off sample area and thus not particularly interesting to the user.\relax }}{2}{figure.caption.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An example of three ROC curves for a binary classification problem. Area Under the Curve (AUC) - the area under each line. The higher the value of AUC the better the model.\relax }}{3}{figure.caption.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces $m/z$ (ion) image example\relax }}{4}{figure.caption.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Single (normalized) spectrum example\relax }}{4}{figure.caption.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Two images above are slices of MSI datasets of regular and irregular shapes. It is pretty easy to see two distinct areas on the first image. On the second one, it is tough to locate the off sample area as it is represented only with a thin ring around the sample.\relax }}{5}{figure.caption.5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:ion_image_regular.png}{{5a}{5}{Rectangular MSI dataset\relax }{figure.caption.5}{}}
\newlabel{sub@fig:ion_image_regular.png}{{a}{5}{Rectangular MSI dataset\relax }{figure.caption.5}{}}
\newlabel{fig:ion_image_irregular.png}{{5b}{5}{Irregular shape MSI dataset\relax }{figure.caption.5}{}}
\newlabel{sub@fig:ion_image_irregular.png}{{b}{5}{Irregular shape MSI dataset\relax }{figure.caption.5}{}}
\newlabel{fig:sum_ints_on_sample_graph.png}{{6a}{5}{Sum of on sample spectra\relax }{figure.caption.6}{}}
\newlabel{sub@fig:sum_ints_on_sample_graph.png}{{a}{5}{Sum of on sample spectra\relax }{figure.caption.6}{}}
\newlabel{fig:sum_ints_off_sample_graph.png}{{6b}{5}{Sum of off sample spectra\relax }{figure.caption.6}{}}
\newlabel{sub@fig:sum_ints_off_sample_graph.png}{{b}{5}{Sum of off sample spectra\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The above two images show sum of spectra for two areas (on/off sample) of a MSI dataset. It is easy to see that there is a difference between these two spectra.\relax }}{5}{figure.caption.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The stacked bars graph is a zoomed version of the above two spectra combined. On this graph, it is easier to see that some signals (at specific $m/z$) come mostly from the off sample while others from the on sample area.\relax }}{6}{figure.caption.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The example mask for a MSI dataset, the mask is in yellow. Each pixel has one of the two classes assigned to it. Correct prediction of such masks for all MSI datasets in focus is one way of solving the original problem. Once we have a mask image for a MSI dataset, it should be possible to combine it with every result image (ion image) from METASPACE for the dataset and decide if the image depicts the off sample or the on sample area.\relax }}{6}{figure.caption.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Another approach would be to try to train a model that takes an ion image as input and classifies it as on/off sample one. Two images from the same MSI dataset, the left one depicts the on sample area, the right off sample.\relax }}{6}{figure.caption.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The PCA tranformation was applied to all pixels of a MSI dataset. Visualisation of the first two components. Pixels that belong to different classes have different colour. Here we can clearly see two groups that also have a substantial overlapping.\relax }}{7}{figure.caption.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces A histogram of the first principal component. It is easy to see that distributions of of component values are quite different for the classes. Unfortunately, not for all MSI datasets in focus it is possible to get such a nice binomial distribution. Another problem with this approach is in the fact that it is not known which class a particular distribution represents, on or off sample. The order of distribution peaks is different for each MSI dataset.\relax }}{7}{figure.caption.11}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Another attempt to use unsupervised learning in order to separate pixels of two different classes. K-means clustering algorithm with $N=5$ ($N$ - number of clusters) was applied to an MSI dataset. The cluster numbers were assigned colours and mapped back to the original pixel locations. One can clearly see a nice grouping of pixels. Here the clusters assigned yellow, green and dark blue colours together represent on sample area.\relax }}{8}{figure.caption.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces A simple illustration of how CNNs work. Two dimensional array (image) as input, a class label as output. Once we have fed enough example images with class labels to the networks, it will hopefully learn (adjust all its weights) to predict classes for new images it has never seen.\relax }}{9}{figure.caption.13}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The core concept of CNNs is image features. One can think of them as a set of small images that that can be extracted from an input image. They can be located in different places on images but still images that have a lot of features in common are considered to be similar. The approach of comparing images by features is much more flexible than full image matching schemes.\relax }}{9}{figure.caption.14}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Convolution is another concept that actually gives the name to the CNNs. Convolution is a way of detecting particular features on images. For that convolutional filters are used, see top left corner. Simple mathematical operations of element-wise multiplication and averaging among all results of the filter application are used for that.\relax }}{9}{figure.caption.15}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Pooling is a technique used in CNN in order to compensate for feature shifts and distortions.\relax }}{9}{figure.caption.16}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Rectified Linear Units (ReLUs). At every convolutional layer after linear operations a non-linear function is applied to the result. ReLUs give CNNs power to capture non-linear relations by simply setting any negative number to zero and not changing positive numbers.\relax }}{10}{figure.caption.17}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces By stacking multiple layers CNNs represent increasingly sophisticated aspects of input images. As outputs from previous layers become inputs for the following ones, the network learns to detect more and more complex features at each layer.\relax }}{10}{figure.caption.18}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces The final layer of any CNN is a dense layer where all the high level features are multiplied by weights and the final votes are made in order to decide on image class.\relax }}{10}{figure.caption.19}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Backpropagation is the algorithm for learning all those parameters the network has. It gets its name from the way it propagates errors from the final layer, where we compare predicted class labels with actual ones, all the way back to the first layer. The higher the error is at a specific layer for a specific image the more parameters of this layer will be corrected.\relax }}{10}{figure.caption.20}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Comparison of on sample (top) and off sample (bottom) ion images.\relax }}{11}{figure.caption.21}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces The final dataset appeared to be slightly unbalanced with approximately 30\% of target class images. But inside image groups (MSI datasets), image classes can be much more imbalanced. In some cases, a group has just a few images of the target class. This fact definitely added complexity to the problem.\relax }}{12}{figure.caption.22}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces The final network architecture\relax }}{15}{figure.caption.23}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Group 10-fold cross-validation metrics\relax }}{16}{figure.caption.24}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Cross-validation mean metrics\relax }}{16}{figure.caption.25}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Cross-validation metrics scatter plot\relax }}{17}{figure.caption.26}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Comparison of on sample ion images (left) with off sample ones (right).\relax }}{18}{figure.caption.27}}
